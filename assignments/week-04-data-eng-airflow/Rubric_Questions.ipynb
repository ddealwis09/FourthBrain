{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e99e78b7",
   "metadata": {},
   "source": [
    "## Algorithm Understanding\n",
    "Feature selection methods are intended to reduce the number of input variables to those that are believed to be most useful to a model in order to predict the target variable. What algorithms can be used to automatically select the most important features (regression, etc..)? Describe at least 3?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba7cf2e",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">**Variance Threshold:**</span>\n",
    "\n",
    "We would ideally like to have features with a wide variance so we get many training examples across the full distribution of the true data at test time and more importantly in production. Here we would set a variance threshold for the features then drop features below the threshold. \n",
    "    \n",
    "<span style=\"color:purple\">**Covariance and Correlation:**</span>\n",
    "\n",
    "Correlation measures the proxmitity of linear association between two variables (between -1 and 1), high correlation values mean the variables tend to move in the same direction (positively or negatively); and low correlation means they tend to move in opposite directions. For feature selection, we want features that have strong correlations (i.e. closer to 1 or -1) with our target variable. We need to be careful here as we need to ensure the features we select are not excessively correlated with each other as this could lead to other issues (e.g. multicolinearity in the linear regression context). \n",
    "\n",
    "<span style=\"color:purple\">**Univariate Methods:**</span>\n",
    "\n",
    "In univariate methods we apply a statistical test to determine whether a single feature should remain in the training data or not. For example, if we were working on a classification problem, we might use a support vector machine (SVM) to calculate its score before and after removing the feature. First we use a statistical test like a p-value to determine the most relevant features then compare that with the SVM pre and post removal. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f00736b",
   "metadata": {},
   "source": [
    "## Interview Readiness 1\n",
    "Explain data leakage and overfitting (define each)?\n",
    "Explain the effect of data leakage and overfitting on the performance of an ML model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bea2d7",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">**Data Leakage:**</span>\n",
    "\n",
    "Data leakage comes in numerous forms from information about the test set *leaking* into the training set to having features in training that may not be available during production. Data leakage will result in overly optimistic outcomes in both training and test.\n",
    "\n",
    "ML model performance issues with data leakage would likely be seen in the form of poor predictions in production environments and going unnoticed in the modelling process (training and test sets). If serious enough, it could lead to the end of the entire modelling and need to go back to the modelling phase of your production pipeline. \n",
    "\n",
    "I've found that using pipelines for pre-processing tasks helps keep data leakage under check. You should also immediately remove any features that you know will not be available in real production environments. \n",
    "\n",
    "<span style=\"color:purple\">**Overfitting:**</span>\n",
    "\n",
    "Overfitting describes the process of a model performing well in training but not generalizing to unseen data well (i.e. test set, production). Overfitting is something that can generally be detected before finalizing your model as your training results will likely be significantly better than your cross-validation and test set results. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ebf8ae",
   "metadata": {},
   "source": [
    "## Interview Readiness 2\n",
    "Explain what our outliers in your data?\n",
    "Explain at least two methods to deal/treat outliers in your data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cd2bbe",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">**Outliers:**</span>\n",
    "    \n",
    "Outliers are observations in your data set that can be considered extreme observations, generally seen as being very from from the mean/median observations (e.g. > 3 standard deviations away). \n",
    "\n",
    "Any given feature should be inspected for outliers to determine the outlier type which will make it easier to determine what to do with it. For example if it was known on a given day, some observations in an experiment were recorded using a faulty measurement device, you may be comfortable removing them from your dataset. Other outliers may in fact be relevant a needed to understand your dataset better and your model should be able to predict these values (e.g. very high priced luxury homes in a house price prediction model). \n",
    "\n",
    "As mentioned, determining what to do with outliers depends on the nature of your information about them. Either way you should use some method or visualization technique to identify outliers in your dataset (e.g. IQR plots).\n",
    "\n",
    "- if you know they are faulty observations you may choose to remove them\n",
    "- alternatively you may not want to delete the observations from your dataset, so you may choose to impute the values somehow (e.g. mean/median)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13aaec2f",
   "metadata": {},
   "source": [
    "## Interview Readiness 3\n",
    "What is feature scaling and why is it important to our model?\n",
    "Explain the different between Normalization and Standardization?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b0049a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
